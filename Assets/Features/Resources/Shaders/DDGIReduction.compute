#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl"
#include "Lib/DDGIInputs.hlsl"
#include "Lib/DDGIProbeIndexing.hlsl"
#include "Lib/DDGIFuncs.hlsl"

// Reference:   https://www.cnblogs.com/OneStargazer/p/18122953
//              https://zhuanlan.zhihu.com/p/469436345
// Currently, Unity does not provide an API to query the Lane Count of the current platform. 
// According to HDRP's definition, we should fall back to a 64-lane count on non-console platforms.
// For NVIDIA GPUs, the lane count is 32, while for AMD GPUs, it is 64. 
// It is currently unclear why HDRP chooses to fall back to 64.

// **However**, we need to use the lane count here to calculate the number of waves (NUM_WAVES), 
// which in turn determines the size of ThreadGroupSum.
// ThreadGroupSum is used to store the reduction results of each wave, 
// and finally, the reduceSharedMemorySum function performs a second reduction on ThreadGroupSum 
// to determine the final reduction result for each thread group.
// If we fall back to a 64-lane count here, then on NVIDIA GPUs, the size of ThreadGroupSum 
// will be insufficient, which could lead to out-of-bounds array access and unpredictable behavior.
// Specifically, based on the readback results of variability average, if lane count = 64, 
// we will get NaN values on NVIDIA GPUs.
// ---------------------------------------------------------------------------------------------------
// Here, we set it to 32. If the GPU is from AMD, then waveIndex will only be 0 and 1, 
// meaning ThreadGroupSum will have two empty slots. 
// In theory, MaxSumEntry will be at most 1, and subsequent accesses to elements 2 and 3 
// of ThreadGroupSum should not occur, so it should be fine.
// However, if some GPUs (such as Intel) have a lane count lower than 32, 
// it may still not work correctly.
#ifdef PLATFORM_LANE_COUNT                                  // Reference HDRP: We can infer the size of a wave. This is currently not possible on non-consoles, so we have to fallback to a sensible default in those cases.
    #define RTXGI_DDGI_WAVE_LANE_COUNT  PLATFORM_LANE_COUNT
#else
    #define RTXGI_DDGI_WAVE_LANE_COUNT  32                  // HDRP falls back to 64 here, but based on the above reasoning, we can only set it to 32.
#endif

#define NUM_THREADS_X 4
#define NUM_THREADS_Y 8
#define NUM_THREADS_Z 4
#define NUM_THREADS NUM_THREADS_X * NUM_THREADS_Y * NUM_THREADS_Z
#define NUM_WAVES   NUM_THREADS / RTXGI_DDGI_WAVE_LANE_COUNT

#pragma kernel DDGIReductionCS
#pragma kernel DDGIExtraReductionCS

// Adding this line allows Wave operations (such as WaveActiveSum) to compile successfully.
#pragma use_dxc

RWTexture2DArray<float>  _ProbeVariability; 
RWTexture2DArray<float2> _ProbeVariabilityAverage;

groupshared float ThreadGroupSum[NUM_WAVES];
groupshared uint  MaxSumEntry;
groupshared uint  NumTotalSamples;

// Sums values in the ThreadGroupSum shared memory array, from 0 to MaxSumEntry
// At the end of the function, ThreadGroupSum[0] should have the total of the whole array
void reduceSharedMemorySum(uint ThreadIndexInGroup, uint waveIndex, uint waveLaneCount)
{
    uint numSharedMemoryEntries = MaxSumEntry + 1;
    uint activeThreads = numSharedMemoryEntries;
    while (activeThreads > 1)
    {
        bool usefulThread = ThreadIndexInGroup < activeThreads;
        if (usefulThread)
        {
            float value = ThreadGroupSum[ThreadIndexInGroup];
            GroupMemoryBarrierWithGroupSync();

            float warpTotalValue = WaveActiveSum(value);

            if (WaveIsFirstLane())
            {
                ThreadGroupSum[waveIndex] = warpTotalValue;
            }
            GroupMemoryBarrierWithGroupSync();
        }
        // Divide by wave size, rounding up (ceil)
        activeThreads = (activeThreads + waveLaneCount - 1) / waveLaneCount;
    }
}

// Thread Group Counts:
//  X - (probeCount.x * interiorIrradianceTexels) / (NUM_THREAD_X * ThreadSampleFootprint.x)
//  Y - (probeCount.y * interiorIrradianceTexels) / (NUM_THREAD_Y * ThreadSampleFootprint.y)
//  Z - (probeCount.z * interiorIrradianceTexels) / NUM_THREAD_Z
// That is, "Given that there are NUM_THREAD_X threads in the X direction, and each thread processes ThreadSampleFootprint.x sample footprints, 
// how many thread groups need to be allocated in the X direction to complete the reduction of the irradiance texture along the X-axis."
[numthreads(NUM_THREADS_X, NUM_THREADS_Y, NUM_THREADS_Z)]
void DDGIReductionCS(uint3 GroupID : SV_GroupID, uint3 GroupThreadID : SV_GroupThreadID, uint ThreadIndexInGroup : SV_GroupIndex)
{
    if (ThreadIndexInGroup == 0)
    {
        MaxSumEntry = 0;
        NumTotalSamples = 0;
    }
    GroupMemoryBarrierWithGroupSync();

    // Doing 4x2 samples per thread
    const uint3 ThreadSampleFootprint = uint3(4, 2, 1);

    uint3 groupCoordOffset   = GroupID.xyz * uint3(NUM_THREADS_X, NUM_THREADS_Y, NUM_THREADS_Z) * ThreadSampleFootprint;
    uint3 threadCoordInGroup = GroupThreadID.xyz;
    uint3 threadCoordGlobal  = groupCoordOffset + threadCoordInGroup * ThreadSampleFootprint;

    uint waveLaneCount       = WaveGetLaneCount();
    uint wavesPerThreadGroup = NUM_THREADS / waveLaneCount;
    uint waveIndex           = ThreadIndexInGroup / waveLaneCount;

    uint3 probeVariabilitySize = _ReductionInputSize;

    float sampleSum  = 0;
    uint  numSamples = 0;
    for (uint i = 0; i < ThreadSampleFootprint.x; i++)
    {
        for (uint j = 0; j < ThreadSampleFootprint.y; j++)
        {
            uint3 sampleCoord = threadCoordGlobal + uint3(i, j, 0);
            // Iterating over non-border samples of the irradiance texture
            // Calling GetProbeIndex with NUM_INTERIOR_TEXELS (instead of NUM_TEXELS) to make
            // sample coordinates line up with probe indices and avoid sampling border texels
            int  probeIndex     = DDGIGetProbeIndex(sampleCoord/*, RTXGI_DDGI_PROBE_NUM_INTERIOR_TEXELS, volume*/);
            bool sampleInBounds = all(sampleCoord < probeVariabilitySize);
            if (sampleInBounds)
            {
                float value = _ProbeVariability[sampleCoord].r;

                // Skip inactive probes
                if (DDGI_PROBE_CLASSIFICATION == DDGI_PROBE_CLASSIFICATION_ON)
                {
                    const uint3 probeDataCoords = DDGIGetProbeTexelCoordsOneByOne(probeIndex);
                    const int   probeState      = DDGILoadProbeState(probeDataCoords);
                    if (probeState == DDGI_PROBE_STATE_INACTIVE)
                    {
                        value = 0.0f;
                        continue;
                    }
                }

                sampleSum += value;
                numSamples++;
            }
        }
    }

    // Sum up the warp
    float waveTotalValue    = WaveActiveSum(sampleSum);
    // Sum up useful sample count
    uint  usefulSampleCount = WaveActiveSum(numSamples);
    // Write sum and sample count for this wave
    if (WaveIsFirstLane())
    {
        ThreadGroupSum[waveIndex] = waveTotalValue;
        InterlockedMax(MaxSumEntry, waveIndex);
        InterlockedAdd(NumTotalSamples, usefulSampleCount);
    }
    GroupMemoryBarrierWithGroupSync();
    reduceSharedMemorySum(ThreadIndexInGroup, waveIndex, waveLaneCount);

    if (ThreadIndexInGroup == 0)
    {
        float TotalPossibleSamples = NUM_THREADS * ThreadSampleFootprint.x * ThreadSampleFootprint.y;
        // Average value for the samples we took
        _ProbeVariabilityAverage[GroupID.xyz].r = NumTotalSamples > 0 ? ThreadGroupSum[0] / NumTotalSamples : 0;
        // Normalizing "weight" factor for this thread group, to allow partial thread groups to average properly with full groups
        _ProbeVariabilityAverage[GroupID.xyz].g = NumTotalSamples / TotalPossibleSamples;
    }
}

groupshared float ThreadGroupAverage[NUM_WAVES];
groupshared uint  MaxAverageEntry;
groupshared float ThreadGroupWeight[NUM_WAVES];

void reduceSharedMemoryAverage(uint ThreadIndexInGroup, uint waveIndex, uint waveLaneCount)
{
    uint numSharedMemoryEntries = MaxAverageEntry + 1;
    uint activeThreads = numSharedMemoryEntries;
    while (activeThreads > 1)
    {
        bool usefulThread = ThreadIndexInGroup < activeThreads;
        if (usefulThread)
        {
            float value = ThreadGroupAverage[ThreadIndexInGroup];
            float weight = ThreadGroupWeight[ThreadIndexInGroup];
            GroupMemoryBarrierWithGroupSync();

            float waveTotalValue = WaveActiveSum(weight*value);
            float waveTotalWeight = WaveActiveSum(weight);
            float TotalPossibleWeight = WaveActiveCountBits(true);

            if (WaveIsFirstLane())
            {
                ThreadGroupAverage[waveIndex] = waveTotalValue / waveTotalWeight;
                ThreadGroupWeight[waveIndex] = waveTotalWeight / TotalPossibleWeight;
            }
            GroupMemoryBarrierWithGroupSync();
        }
        activeThreads = (activeThreads + waveLaneCount - 1) / waveLaneCount;
    }
}

[numthreads(NUM_THREADS_X, NUM_THREADS_Y, NUM_THREADS_Z)]
void DDGIExtraReductionCS(uint3 GroupID : SV_GroupID, uint3 GroupThreadID : SV_GroupThreadID, uint ThreadIndexInGroup : SV_GroupIndex)
{
    if (ThreadIndexInGroup == 0)
    {
        MaxAverageEntry = 0;
    }
    GroupMemoryBarrierWithGroupSync();
    
    uint waveLaneCount = WaveGetLaneCount();
    uint wavesPerThreadGroup = NUM_THREADS / waveLaneCount;
    uint waveIndex = ThreadIndexInGroup / waveLaneCount;

    // Doing 4x2 samples per thread
    const uint3 ThreadSampleFootprint = uint3(4, 2, 1);

    uint3 groupCoordOffset = GroupID.xyz * uint3(NUM_THREADS_X, NUM_THREADS_Y, NUM_THREADS_Z) * ThreadSampleFootprint;
    uint3 threadCoordInGroup = GroupThreadID.xyz;
    uint3 threadCoordGlobal = groupCoordOffset + threadCoordInGroup * ThreadSampleFootprint;
    uint3 inputSize = _ReductionInputSize;
    
    bool footprintInBounds = all(threadCoordGlobal < inputSize);
    float threadFootprintValueSum = 0;
    float threadFootprintWeightSum = 0;

    if (footprintInBounds)
    {
        for (uint i = 0; i < ThreadSampleFootprint.x; i++)
        {
            for (uint j = 0; j < ThreadSampleFootprint.y; j++)
            {
                uint3 sampleCoord = threadCoordGlobal + uint3(i, j, 0);
                bool sampleInBounds = all(sampleCoord < inputSize);
                if (sampleInBounds)
                {
                    float value = _ProbeVariabilityAverage[sampleCoord].r;
                    float weight = _ProbeVariabilityAverage[sampleCoord].g;
                    threadFootprintValueSum += weight * value;
                    threadFootprintWeightSum += weight;
                }
            }
        }
    }
    float threadAverageValue = (footprintInBounds && threadFootprintWeightSum > 0) ? threadFootprintValueSum / threadFootprintWeightSum : 0;
    // Per-thread weight will be 1.0 if thread sampled all 4x2 pixels, 0.125 if it only sampled one
    float ThreadTotalPossibleWeight = ThreadSampleFootprint.x * ThreadSampleFootprint.y;
    float threadWeight = threadFootprintWeightSum / ThreadTotalPossibleWeight;

    // Sum up the warp
    float waveTotalValue = WaveActiveSum(threadWeight * threadAverageValue);
    float waveTotalWeight = WaveActiveSum(threadWeight);
    float waveTotalPossibleWeight = waveLaneCount * ThreadTotalPossibleWeight;

    if (WaveIsFirstLane() && WaveActiveAnyTrue(footprintInBounds))
    {
        ThreadGroupAverage[waveIndex] = waveTotalValue / waveTotalWeight;
        ThreadGroupWeight[waveIndex] = waveTotalWeight / waveTotalPossibleWeight;
        InterlockedMax(MaxSumEntry, waveIndex);
    }

    GroupMemoryBarrierWithGroupSync();
    reduceSharedMemoryAverage(ThreadIndexInGroup, waveIndex, waveLaneCount);
    if (ThreadIndexInGroup == 0)
    {
        _ProbeVariabilityAverage[GroupID.xyz].r = ThreadGroupAverage[0];
        _ProbeVariabilityAverage[GroupID.xyz].g = ThreadGroupWeight[0];
    }
}